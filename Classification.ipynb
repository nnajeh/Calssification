{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3edd999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.datasets as dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import autograd, optim\n",
    "\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a14090f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db2f24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = ['train', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac0c1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in phase:\n",
    "    files = glob.glob(os.path.join(path+p, '*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14179c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(path+p, '*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72ca2fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    }
   ],
   "source": [
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "712ee9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_images =len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47995e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = np.random.permutation(no_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7e3a8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.485,0.465,0.406),(0.229,0.224,0.225))\n",
    "                                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e371789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.ImageFolder(path+'train', transform)\n",
    "valid_dataset = dataset.ImageFolder(path+'valid', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b3bf93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConcatDataset([train_dataset, valid_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2e5bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b225a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = random_split(train_dataset, [train_size-200, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ed22816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6005\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850c4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size= 16, shuffle= True)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size= 16, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3d70a",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57290655",
   "metadata": {},
   "source": [
    "- Load pretrained model ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d47d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "056df003",
   "metadata": {},
   "source": [
    "- the loaded model  trained to predict 1000 different categories\n",
    "\n",
    "--> We need to change the model to predict the number of classes of the dataset (2 classes)\n",
    "--> To do that, take the last layer pof the ResNet model \"Linear layer\" and change the output features to \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dc82d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45467e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6855315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the GPU\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8aa8160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function\n",
    "crit = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "897a8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4250f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helps to dynamically change the learning rate\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size = 7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba155f",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406117bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15bfe861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.1005421936427778 \t\t Validation Loss: 0.00017408856749534608\n",
      "Validation Loss Decreased(inf--->0.021761) \t Saving The Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-6fc82ce6fa3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calculates the gradients quentity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#save changes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for i,(data,labels) in enumerate (train_dataloader):\n",
    "        image = data.cuda()\n",
    "        label = labels.cuda()\n",
    "         \n",
    "        # Clear the gradients    \n",
    "        model.zero_grad()\n",
    "        \n",
    "        #forward\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = crit(outputs, label)\n",
    "        \n",
    "        loss.backward() #calculates the gradients quentity \n",
    "        opt.step()#save changes\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "    for i, (data, labels) in enumerate(valid_dataloader):\n",
    "        image = data.cuda()\n",
    "        label = labels.cuda()\n",
    "        \n",
    "        target = model(image)\n",
    "        loss = crit(target, label)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "         \n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {running_loss / len(train_dataloader)} \\t\\t Validation Loss: {valid_loss / len(valid_dataloader)}')\n",
    "    \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'saved_model.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46854bb",
   "metadata": {},
   "source": [
    "# Add Cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d8ba85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#do the training for different 5 iterations\n",
    "k_folds = 4\n",
    "\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60fb717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1 \t\t Training Loss: 0.12147235691837194 \t\t Validation Loss: 1.0004269887696017e-06\n",
      "Validation Loss Decreased(inf--->0.002003) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 0.04655375749419537 \t\t Validation Loss: 3.7560004510216186e-06\n",
      "Epoch 3 \t\t Training Loss: 0.0330657532170122 \t\t Validation Loss: 2.179303038218705e-08\n",
      "Validation Loss Decreased(0.002003--->0.000044) \t Saving The Model\n",
      "Epoch 4 \t\t Training Loss: 0.02549827255277589 \t\t Validation Loss: 2.0818581949309124e-07\n",
      "Epoch 5 \t\t Training Loss: 0.023994107772639526 \t\t Validation Loss: 1.908817605769539e-06\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1 \t\t Training Loss: 0.04762444016163732 \t\t Validation Loss: 2.210178301201436e-08\n",
      "Epoch 2 \t\t Training Loss: 0.019528194136155627 \t\t Validation Loss: 1.3598506904390084e-06\n",
      "Epoch 3 \t\t Training Loss: 0.011678242226683691 \t\t Validation Loss: 5.957485379577905e-11\n",
      "Validation Loss Decreased(0.000044--->0.000000) \t Saving The Model\n",
      "Epoch 4 \t\t Training Loss: 0.008862489783234893 \t\t Validation Loss: 3.1084014937795443e-06\n",
      "Epoch 5 \t\t Training Loss: 0.01512463849662902 \t\t Validation Loss: 0.0\n",
      "Validation Loss Decreased(0.000000--->0.000000) \t Saving The Model\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1 \t\t Training Loss: 0.023271276825943595 \t\t Validation Loss: 2.382993725718577e-10\n",
      "Epoch 2 \t\t Training Loss: 0.007027152046219349 \t\t Validation Loss: 6.851061779303129e-09\n",
      "Epoch 3 \t\t Training Loss: 0.006931636340300913 \t\t Validation Loss: 1.1438241708783554e-08\n",
      "Epoch 4 \t\t Training Loss: 0.005191768741281792 \t\t Validation Loss: 1.2331843661060133e-08\n",
      "Epoch 5 \t\t Training Loss: 0.003787336074550056 \t\t Validation Loss: 6.560840574593499e-07\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1 \t\t Training Loss: 0.00522517750665729 \t\t Validation Loss: 5.957482325771046e-10\n",
      "Epoch 2 \t\t Training Loss: 0.003787597801243329 \t\t Validation Loss: 0.0\n",
      "Epoch 3 \t\t Training Loss: 0.0025663369724038313 \t\t Validation Loss: 4.9385116876580976e-08\n",
      "Epoch 4 \t\t Training Loss: 0.0028616824832924785 \t\t Validation Loss: 0.0\n",
      "Epoch 5 \t\t Training Loss: 0.0022839475792386325 \t\t Validation Loss: 5.957485379577905e-11\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate((kfold.split(dataset))):\n",
    "  # Print\n",
    "  print('----------------------------------------------------------------------------')\n",
    "  print(f'----------------------------FOLD {fold}------------------------------------')\n",
    "  print('----------------------------------------------------------------------------')\n",
    "        \n",
    "  # Sample elements randomly from a given list of ids, no replacement.\n",
    "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "  val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "\n",
    "  # Define data loaders for training and testing data in this fold\n",
    "  train_dataloader = DataLoader(dataset, batch_size=16, sampler=train_subsampler)\n",
    "  valid_dataloader = DataLoader(dataset, batch_size=1, sampler=val_subsampler)\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for i,(data,labels) in enumerate (train_dataloader):\n",
    "        image = data.cuda()\n",
    "        label = labels.cuda()\n",
    "         \n",
    "        # Clear the gradients    \n",
    "        model.zero_grad()\n",
    "        \n",
    "        #forward\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = crit(outputs, label)\n",
    "        \n",
    "        loss.backward() #calculates the gradients quentity \n",
    "        opt.step()#save changes\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, (data, labels) in enumerate(valid_dataloader):\n",
    "        image = data.cuda()\n",
    "        label = labels.cuda()\n",
    "        \n",
    "        target = model(image)\n",
    "        loss = crit(target, label)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "         \n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {running_loss / len(train_dataloader)} \\t\\t Validation Loss: {valid_loss / len(valid_dataloader)}')\n",
    "    \n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'saved_model.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340850c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
